{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPz4IZzMgCwioC+vh1ZhIXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MangeshVR1546/Satellite-Imagery-Based-Property-Valuation-Project/blob/main/multimodel_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline model training using only tabular data**"
      ],
      "metadata": {
        "id": "y-B2i5tg06Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# 1. Load your training data (tabular only)\n",
        "df = pd.read_csv(\"/content/train(1)(train(1)).csv\")\n",
        "\n",
        "# 2. Basic preprocessing / feature selection\n",
        "#    Adjust this list to match the columns you want to use\n",
        "feature_cols = [\n",
        "    \"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\",\n",
        "    \"floors\", \"waterfront\", \"view\", \"condition\", \"grade\",\n",
        "    \"sqft_above\", \"sqft_basement\", \"lat\", \"long\",\n",
        "    \"sqft_living15\", \"sqft_lot15\"\n",
        "]\n",
        "\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[\"price\"])\n",
        "\n",
        "X = df[feature_cols].fillna(0)\n",
        "y = df[\"price\"].values\n",
        "\n",
        "# Optional: log-transform target for numeric stability\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# 3. Train/validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 4. Scale features (helps tree models a bit; essential for linear models)\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "\n",
        "# 5. Baseline model: XGBoost regressor (tabular only)\n",
        "model = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    tree_method=\"hist\"\n",
        ")\n",
        "model.fit(X_train_s, y_train)\n",
        "\n",
        "# 6. Evaluation: R² and price RMSE\n",
        "y_val_pred_log = model.predict(X_val_s)\n",
        "\n",
        "# Convert back to price space\n",
        "y_val_true_price = np.expm1(y_val)\n",
        "y_val_pred_price = np.expm1(y_val_pred_log)\n",
        "\n",
        "r2 = r2_score(y_val_true_price, y_val_pred_price)          # [web:275][web:285]\n",
        "rmse = np.sqrt(mean_squared_error(y_val_true_price, y_val_pred_price))  # [web:283][web:281]\n",
        "\n",
        "print(\"=== Baseline Tabular Model ===\")\n",
        "print(f\"R² score:       {r2:.4f}\")\n",
        "print(f\"Price RMSE:     ${rmse:,.0f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te2rxKRF01PE",
        "outputId": "165c2496-60e1-4dca-bab8-d153128afc37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Baseline Tabular Model ===\n",
            "R² score:       0.8859\n",
            "Price RMSE:     $119,645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multimodel Training**\n",
        "\n"
      ],
      "metadata": {
        "id": "rjSP2ysFytyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJJufSbGyebI",
        "outputId": "d053ebaa-b01e-4d22-9688-cb13249496fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.6)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading category_encoders-2.9.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna, category_encoders\n",
            "Successfully installed category_encoders-2.9.0 colorlog-6.10.1 optuna-4.6.0\n",
            "Tabular: 16209 | Images: 3241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-01-04 16:29:21,249] A new study created in memory with name: no-name-0a81d888-1b7e-4464-8017-906954a89ae9\n",
            "[I 2026-01-04 16:30:08,072] Trial 0 finished with value: 0.20503230726484747 and parameters: {'n_estimators': 1674, 'learning_rate': 0.013953586037052972, 'max_depth': 9, 'subsample': 0.944475261915234, 'colsample_bytree': 0.9101016803225842, 'reg_alpha': 1.654595085160443, 'reg_lambda': 0.04392755508293196, 'min_child_weight': 6}. Best is trial 0 with value: 0.20503230726484747.\n",
            "[I 2026-01-04 16:30:31,565] Trial 1 finished with value: 0.19925702970746612 and parameters: {'n_estimators': 1178, 'learning_rate': 0.03364255673576441, 'max_depth': 7, 'subsample': 0.9381116126585299, 'colsample_bytree': 0.8142704981064148, 'reg_alpha': 0.022224158188512935, 'reg_lambda': 1.5202857519788304, 'min_child_weight': 5}. Best is trial 1 with value: 0.19925702970746612.\n",
            "[I 2026-01-04 16:30:57,228] Trial 2 finished with value: 0.19847260530031605 and parameters: {'n_estimators': 1204, 'learning_rate': 0.01940853644216582, 'max_depth': 7, 'subsample': 0.984049226260479, 'colsample_bytree': 0.8891004005118043, 'reg_alpha': 0.002329963646250583, 'reg_lambda': 1.2913860890452755, 'min_child_weight': 7}. Best is trial 2 with value: 0.19847260530031605.\n",
            "[I 2026-01-04 16:31:34,999] Trial 3 finished with value: 0.197047038543562 and parameters: {'n_estimators': 1662, 'learning_rate': 0.010393735930281011, 'max_depth': 7, 'subsample': 0.9543478770429038, 'colsample_bytree': 0.8102210897645106, 'reg_alpha': 0.30033846756014193, 'reg_lambda': 4.202461792494052, 'min_child_weight': 8}. Best is trial 3 with value: 0.197047038543562.\n",
            "[I 2026-01-04 16:32:03,377] Trial 4 finished with value: 0.20092389725701412 and parameters: {'n_estimators': 1229, 'learning_rate': 0.04869560973748824, 'max_depth': 8, 'subsample': 0.968099217429743, 'colsample_bytree': 0.806310150075695, 'reg_alpha': 0.7096703530800645, 'reg_lambda': 0.006556798191397093, 'min_child_weight': 8}. Best is trial 3 with value: 0.197047038543562.\n",
            "[I 2026-01-04 16:32:37,378] Trial 5 finished with value: 0.19956307795438388 and parameters: {'n_estimators': 831, 'learning_rate': 0.0395572680546838, 'max_depth': 9, 'subsample': 0.8118032657294153, 'colsample_bytree': 0.915283353650621, 'reg_alpha': 0.0027591715912476406, 'reg_lambda': 0.01939861589364723, 'min_child_weight': 9}. Best is trial 3 with value: 0.197047038543562.\n",
            "[I 2026-01-04 16:33:04,505] Trial 6 finished with value: 0.19466422084867874 and parameters: {'n_estimators': 869, 'learning_rate': 0.025703561067400155, 'max_depth': 6, 'subsample': 0.8906898039888749, 'colsample_bytree': 0.8713741504739173, 'reg_alpha': 0.07053145957798182, 'reg_lambda': 2.3658948377239746, 'min_child_weight': 6}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:33:24,542] Trial 7 finished with value: 0.19933985488824693 and parameters: {'n_estimators': 1625, 'learning_rate': 0.01973455082126701, 'max_depth': 5, 'subsample': 0.8046040560022085, 'colsample_bytree': 0.8583083271926835, 'reg_alpha': 1.9795239594905947, 'reg_lambda': 0.02832888304501059, 'min_child_weight': 9}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:33:40,816] Trial 8 finished with value: 0.2000145530269568 and parameters: {'n_estimators': 942, 'learning_rate': 0.0344193557336012, 'max_depth': 5, 'subsample': 0.966770613405228, 'colsample_bytree': 0.9062679243161971, 'reg_alpha': 2.333680451066604, 'reg_lambda': 0.01189566429400616, 'min_child_weight': 9}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:34:00,151] Trial 9 finished with value: 0.19906975906654603 and parameters: {'n_estimators': 1454, 'learning_rate': 0.042510562078023964, 'max_depth': 6, 'subsample': 0.9815445696190457, 'colsample_bytree': 0.964395531816424, 'reg_alpha': 0.7278804404665193, 'reg_lambda': 0.07745069114709936, 'min_child_weight': 6}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:34:35,763] Trial 10 finished with value: 0.1966961225264808 and parameters: {'n_estimators': 1935, 'learning_rate': 0.026330758843351933, 'max_depth': 6, 'subsample': 0.869695536256181, 'colsample_bytree': 0.9918685099096486, 'reg_alpha': 0.038436020175236965, 'reg_lambda': 0.2240665335302827, 'min_child_weight': 2}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:35:10,272] Trial 11 finished with value: 0.1962469525335436 and parameters: {'n_estimators': 1976, 'learning_rate': 0.025154228040396295, 'max_depth': 6, 'subsample': 0.866482370146684, 'colsample_bytree': 0.9663837137144118, 'reg_alpha': 0.03078040888067908, 'reg_lambda': 0.28277089987115395, 'min_child_weight': 2}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:35:42,540] Trial 12 finished with value: 0.19572115574424484 and parameters: {'n_estimators': 1957, 'learning_rate': 0.026847694465349008, 'max_depth': 6, 'subsample': 0.8807849019860311, 'colsample_bytree': 0.9475875114511083, 'reg_alpha': 0.010883572352852302, 'reg_lambda': 0.2873615519903854, 'min_child_weight': 3}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:35:58,920] Trial 13 finished with value: 0.1979271354874388 and parameters: {'n_estimators': 1023, 'learning_rate': 0.02825446808496697, 'max_depth': 6, 'subsample': 0.9022741139615459, 'colsample_bytree': 0.9455317833090655, 'reg_alpha': 0.008374486501344803, 'reg_lambda': 0.0016180381823502569, 'min_child_weight': 4}. Best is trial 6 with value: 0.19466422084867874.\n",
            "[I 2026-01-04 16:36:16,264] Trial 14 finished with value: 0.192455352924879 and parameters: {'n_estimators': 1423, 'learning_rate': 0.01593686104317204, 'max_depth': 5, 'subsample': 0.8943718347493657, 'colsample_bytree': 0.8587199962289483, 'reg_alpha': 0.13009839373595383, 'reg_lambda': 0.4625360851167616, 'min_child_weight': 4}. Best is trial 14 with value: 0.192455352924879.\n",
            "[I 2026-01-04 16:36:32,677] Trial 15 finished with value: 0.19379824298809745 and parameters: {'n_estimators': 1489, 'learning_rate': 0.015610746059143019, 'max_depth': 5, 'subsample': 0.9070143740913226, 'colsample_bytree': 0.8527709394195833, 'reg_alpha': 0.13421520389649783, 'reg_lambda': 1.453950784422966, 'min_child_weight': 4}. Best is trial 14 with value: 0.192455352924879.\n",
            "[I 2026-01-04 16:36:50,026] Trial 16 finished with value: 0.19226102220699268 and parameters: {'n_estimators': 1408, 'learning_rate': 0.015085312132421473, 'max_depth': 5, 'subsample': 0.9203328147471239, 'colsample_bytree': 0.8415955927665577, 'reg_alpha': 0.18690742709777752, 'reg_lambda': 0.7186100130597171, 'min_child_weight': 1}. Best is trial 16 with value: 0.19226102220699268.\n",
            "[I 2026-01-04 16:37:08,185] Trial 17 finished with value: 0.19179130732855112 and parameters: {'n_estimators': 1358, 'learning_rate': 0.013570915349930823, 'max_depth': 5, 'subsample': 0.8388027016632419, 'colsample_bytree': 0.8403162455054533, 'reg_alpha': 0.2125273619010869, 'reg_lambda': 0.5478539895415251, 'min_child_weight': 1}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:38:25,827] Trial 18 finished with value: 0.19959265370223614 and parameters: {'n_estimators': 1276, 'learning_rate': 0.010812134244266474, 'max_depth': 8, 'subsample': 0.8534947611357472, 'colsample_bytree': 0.8383109304264587, 'reg_alpha': 0.269118899941102, 'reg_lambda': 0.6313639565632128, 'min_child_weight': 1}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:38:39,355] Trial 19 finished with value: 0.19241106615789827 and parameters: {'n_estimators': 1079, 'learning_rate': 0.012894843219541426, 'max_depth': 5, 'subsample': 0.8260389597600012, 'colsample_bytree': 0.8368840025770917, 'reg_alpha': 0.5734323066517818, 'reg_lambda': 0.07907200410983563, 'min_child_weight': 1}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:39:56,269] Trial 20 finished with value: 0.20355933469854273 and parameters: {'n_estimators': 1806, 'learning_rate': 0.018449873311854607, 'max_depth': 8, 'subsample': 0.9163935623253404, 'colsample_bytree': 0.8856449110934634, 'reg_alpha': 0.09136569129304287, 'reg_lambda': 0.13047590119449168, 'min_child_weight': 2}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:40:09,919] Trial 21 finished with value: 0.19186350620689166 and parameters: {'n_estimators': 1084, 'learning_rate': 0.011704311149662139, 'max_depth': 5, 'subsample': 0.8348054139427791, 'colsample_bytree': 0.8408126310902211, 'reg_alpha': 0.4973655033764819, 'reg_lambda': 0.5726915404841746, 'min_child_weight': 1}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:40:27,124] Trial 22 finished with value: 0.19198018714672127 and parameters: {'n_estimators': 1313, 'learning_rate': 0.012362302500964524, 'max_depth': 5, 'subsample': 0.8328310742613634, 'colsample_bytree': 0.8306534860942035, 'reg_alpha': 0.31388971628760104, 'reg_lambda': 0.6468169260839663, 'min_child_weight': 1}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:40:42,144] Trial 23 finished with value: 0.19239809980650954 and parameters: {'n_estimators': 1324, 'learning_rate': 0.012114571007695132, 'max_depth': 5, 'subsample': 0.8353472162514068, 'colsample_bytree': 0.8243963718609749, 'reg_alpha': 0.5671982874916771, 'reg_lambda': 0.7323342746663025, 'min_child_weight': 3}. Best is trial 17 with value: 0.19179130732855112.\n",
            "[I 2026-01-04 16:40:55,552] Trial 24 finished with value: 0.1914536760155207 and parameters: {'n_estimators': 1091, 'learning_rate': 0.011996603753209573, 'max_depth': 5, 'subsample': 0.8354656619360998, 'colsample_bytree': 0.8239780697051482, 'reg_alpha': 0.36500456962448596, 'reg_lambda': 0.16949206848151993, 'min_child_weight': 1}. Best is trial 24 with value: 0.1914536760155207.\n",
            "[I 2026-01-04 16:41:16,762] Trial 25 finished with value: 0.19838785651103855 and parameters: {'n_estimators': 1091, 'learning_rate': 0.010134504431027059, 'max_depth': 6, 'subsample': 0.8503417021748111, 'colsample_bytree': 0.8770507093957832, 'reg_alpha': 1.2901487511756815, 'reg_lambda': 0.15062396272525308, 'min_child_weight': 3}. Best is trial 24 with value: 0.1914536760155207.\n",
            "[I 2026-01-04 16:41:29,949] Trial 26 finished with value: 0.19244592563426025 and parameters: {'n_estimators': 1109, 'learning_rate': 0.011714039129141289, 'max_depth': 5, 'subsample': 0.8203103514232234, 'colsample_bytree': 0.8248613004674389, 'reg_alpha': 0.07186073181643253, 'reg_lambda': 3.6201326778626264, 'min_child_weight': 2}. Best is trial 24 with value: 0.1914536760155207.\n",
            "[I 2026-01-04 16:41:49,578] Trial 27 finished with value: 0.2077238820183804 and parameters: {'n_estimators': 960, 'learning_rate': 0.014273311363276293, 'max_depth': 7, 'subsample': 0.8547312945300706, 'colsample_bytree': 0.850088451394604, 'reg_alpha': 3.343556687673401, 'reg_lambda': 0.15493794385435472, 'min_child_weight': 1}. Best is trial 24 with value: 0.1914536760155207.\n",
            "[I 2026-01-04 16:42:00,703] Trial 28 finished with value: 0.1955986073873859 and parameters: {'n_estimators': 985, 'learning_rate': 0.017244591931866695, 'max_depth': 5, 'subsample': 0.8419117860416946, 'colsample_bytree': 0.8186134689643569, 'reg_alpha': 1.0908001718068212, 'reg_lambda': 0.32634948869844876, 'min_child_weight': 2}. Best is trial 24 with value: 0.1914536760155207.\n",
            "[I 2026-01-04 16:42:19,001] Trial 29 finished with value: 0.20511485363687038 and parameters: {'n_estimators': 1574, 'learning_rate': 0.01365906226475571, 'max_depth': 6, 'subsample': 0.8168502888057753, 'colsample_bytree': 0.8032953312063394, 'reg_alpha': 4.8999895745168685, 'reg_lambda': 0.04912460714095297, 'min_child_weight': 3}. Best is trial 24 with value: 0.1914536760155207.\n",
            "[I 2026-01-04 16:42:32,144] Trial 30 finished with value: 0.1932387453751177 and parameters: {'n_estimators': 1158, 'learning_rate': 0.02245755180815302, 'max_depth': 5, 'subsample': 0.8034674038231557, 'colsample_bytree': 0.8723492153331223, 'reg_alpha': 0.24448710514679314, 'reg_lambda': 1.0796340871578018, 'min_child_weight': 5}. Best is trial 24 with value: 0.1914536760155207.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Multimodal House Price Prediction Pipeline\n",
        "Tabular + Satellite Image Features → XGBoost → Price Prediction\n",
        "\"\"\"\n",
        "%pip install category_encoders optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "def train_multimodal_pipeline(tabular_path, img_features_path, img_ids_path):\n",
        "    # Load data\n",
        "    tabular_data = pd.read_csv(tabular_path)\n",
        "    image_features = np.load(img_features_path)\n",
        "    img_house_ids = pd.read_csv(img_ids_path)['id'].values\n",
        "\n",
        "    print(f\"Tabular: {len(tabular_data)} | Images: {len(image_features)}\")\n",
        "\n",
        "    # Align\n",
        "    common_ids = np.intersect1d(tabular_data['id'].values, img_house_ids)\n",
        "    tab_aligned = tabular_data[tabular_data['id'].isin(common_ids)].reset_index(drop=True)\n",
        "    img_idx = [np.where(img_house_ids == id_)[0][0] for id_ in tab_aligned['id']]\n",
        "    img_aligned = image_features[img_idx]\n",
        "\n",
        "    # Zipcode encoding\n",
        "    zip_encoder = TargetEncoder(cols=['zipcode'])\n",
        "    tab_aligned['zipcode_encoded'] = zip_encoder.fit_transform(\n",
        "        tab_aligned[['zipcode']], np.log1p(tab_aligned['price'])\n",
        "    )['zipcode']\n",
        "\n",
        "    # Features (21 tabular)\n",
        "    tab_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
        "                    'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
        "                    'sqft_basement', 'lat', 'long', 'sqft_living15', 'sqft_lot15',\n",
        "                    'log_dist_city', 'log_dist_water', 'log_dist_tech',\n",
        "                    'location_cluster', 'is_renovated', 'zipcode_encoded']\n",
        "\n",
        "    X_tab = tab_aligned[tab_features].fillna(0).values\n",
        "    X_img = img_aligned\n",
        "    y = np.log1p(tab_aligned['price'].values)\n",
        "\n",
        "    # Split\n",
        "    X_tab_train, X_tab_val, X_img_train, X_img_val, y_train, y_val = train_test_split(\n",
        "        X_tab, X_img, y, test_size=0.2, random_state=12345\n",
        "    )\n",
        "\n",
        "    # Scale tabular\n",
        "    tab_scaler = RobustScaler()\n",
        "    X_tab_train_s = tab_scaler.fit_transform(X_tab_train)\n",
        "    X_tab_val_s = tab_scaler.transform(X_tab_val)\n",
        "\n",
        "    # Scale + PCA images\n",
        "    img_scaler = RobustScaler()\n",
        "    X_img_train_s = img_scaler.fit_transform(X_img_train)\n",
        "    X_img_val_s = img_scaler.transform(X_img_val)\n",
        "\n",
        "    pca = PCA(n_components=64, random_state=42)\n",
        "    X_img_train_pca = pca.fit_transform(X_img_train_s)\n",
        "    X_img_val_pca = pca.transform(X_img_val_s)\n",
        "\n",
        "    # Multimodal\n",
        "    X_train_mm = np.hstack([X_tab_train_s, X_img_train_pca])\n",
        "    X_val_mm = np.hstack([X_tab_val_s, X_img_val_pca])\n",
        "\n",
        "    # Optuna\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 800, 2000),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
        "            'max_depth': trial.suggest_int('max_depth', 5, 9),\n",
        "            'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1.0),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 5.0, log=True),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 5.0, log=True),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "            'random_state': 42, 'tree_method': 'hist'\n",
        "        }\n",
        "        model = XGBRegressor(**params)\n",
        "        model.fit(X_train_mm, y_train)\n",
        "        return np.sqrt(mean_squared_error(y_val, model.predict(X_val_mm)))\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=50)\n",
        "\n",
        "    # Best model\n",
        "    best_params = study.best_params.copy()\n",
        "    best_params.update({'random_state': 42, 'tree_method': 'hist'})\n",
        "    final_model = XGBRegressor(**best_params)\n",
        "    final_model.fit(X_train_mm, y_train)\n",
        "\n",
        "    # Pipeline\n",
        "    pipeline = {\n",
        "        'model': final_model, 'tab_scaler': tab_scaler, 'img_scaler': img_scaler,\n",
        "        'pca': pca, 'zip_encoder': zip_encoder, 'tab_features': tab_features,\n",
        "        'img_dim': 512, 'study': study\n",
        "    }\n",
        "    joblib.dump(pipeline, 'multimodal_pipeline.pkl')\n",
        "\n",
        "    # Metrics\n",
        "    y_pred = final_model.predict(X_val_mm)\n",
        "    print(f\"R²: {r2_score(y_val, y_pred):.4f}\")\n",
        "    print(f\"Price RMSE: ${np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(y_pred))):,.0f}\")\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "# Run\n",
        "pipeline = train_multimodal_pipeline(\n",
        "    '/content/preprocessed_data.csv',\n",
        "    '/content/image_features_training.npy',\n",
        "    '/content/image_feature_ids_training.csv'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Price prediction using multimodel on Test_data**"
      ],
      "metadata": {
        "id": "mhA2fJ1w2g07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Live Satellite Prediction for Test Set\n",
        "House lat/lon → Mapbox → ResNet50 → Features → Model\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "\n",
        "def predict_test_set_live_satellite(test_path, pipeline_path='multimodal_pipeline.pkl', mapbox_token=None):\n",
        "    # Load data\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    pipeline = joblib.load(pipeline_path)\n",
        "\n",
        "    print(f\"Predicting {len(test_df)} test houses with LIVE satellite\")\n",
        "\n",
        "    # Dedupe\n",
        "    test_df = test_df.drop_duplicates(subset=['id'], keep='first').reset_index(drop=True)\n",
        "\n",
        "    # Zipcode encoding\n",
        "    test_df['zipcode_encoded'] = pipeline['zip_encoder'].transform(test_df[['zipcode']])['zipcode']\n",
        "\n",
        "    # ResNet50 feature extractor\n",
        "    model_feat = models.resnet50(pretrained=True)\n",
        "    model_feat.fc = torch.nn.Identity()\n",
        "    model_feat.eval()\n",
        "    preprocess = T.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for idx, house in test_df.iterrows():\n",
        "        print(f\"Processing house {house['id']} ({idx+1}/{len(test_df)})\")\n",
        "\n",
        "        # Tabular features\n",
        "        X_tab = house[pipeline['tab_features']].values.reshape(1, -1)\n",
        "        X_tab_s = pipeline['tab_scaler'].transform(X_tab)\n",
        "\n",
        "        # LIVE SATELLITE IMAGE\n",
        "        url = f\"https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/{house['long']},{house['lat']},18/512x512@2x?access_token={mapbox_token}\"\n",
        "        img_data = requests.get(url, timeout=10).content\n",
        "        img = Image.open(io.BytesIO(img_data)).convert('RGB')\n",
        "\n",
        "        # Extract SPECIFIC house features\n",
        "        img_t = preprocess(img).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            img_feat = model_feat(img_t).numpy().flatten()[:512]  # Match training dim\n",
        "\n",
        "        # Transform image features\n",
        "        X_img_s = pipeline['img_scaler'].transform(img_feat.reshape(1, -1))\n",
        "        X_img_pca = pipeline['pca'].transform(X_img_s)\n",
        "\n",
        "        # Multimodal prediction\n",
        "        X_mm = np.hstack([X_tab_s, X_img_pca])\n",
        "        pred_log = pipeline['model'].predict(X_mm)[0]\n",
        "        pred_price = np.expm1(pred_log).round(0)\n",
        "        predictions.append(pred_price)\n",
        "\n",
        "    # Submission\n",
        "    submission = pd.DataFrame({\n",
        "        'id': test_df['id'].astype(int),\n",
        "        'predicted_price': predictions\n",
        "    })\n",
        "    submission.to_csv('24117072_final.csv', index=False)\n",
        "\n",
        "    print(f\"✅ 24117072_final.csv saved: {len(submission)} predictions\")\n",
        "    return submission\n",
        "\n",
        "# Usage\n",
        "MAPBOX_TOKEN = \"pk.eyJ1IjoibWFuZ2VzaDExMTExIiwiYSI6ImNtanlyc2ZqZTBmcmYzZnNjc2Z6bzl0MTAifQ.62QGA4F-FifDpt1b5k9L8A\"\n",
        "submission = predict_test_set_live_satellite(\n",
        "    '/content/preprocessed_data.csv',\n",
        "    mapbox_token=MAPBOX_TOKEN\n",
        ")\n"
      ],
      "metadata": {
        "id": "paOhu2Xa2b0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iagNRme810vB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}